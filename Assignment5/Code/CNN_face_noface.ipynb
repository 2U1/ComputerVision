{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incomplete-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93049b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten_image(image_list):\n",
    "    new_list = []\n",
    "    for image in image_list:\n",
    "        new_list.append(image.reshape(1,32,32))\n",
    "\n",
    "    return np.array(new_list, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad6c8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as fo:\n",
    "        data = pickle.load(fo)\n",
    "\n",
    "    data = unflatten_image(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a0e763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = load_pickle('../data/faces_python.pkl')\n",
    "non_face = load_pickle('../data/nonfaces_python.pkl')\n",
    "face_label = np.ones(face.shape[0],dtype=np.int64)\n",
    "non_face_label = np.zeros(non_face.shape[0], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0c20a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I changed the ratio to 0.8, because I think the training dataset need a larger portion\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "tmp1 = np.round(face.shape[0]*train_test_ratio).astype(int)\n",
    "\n",
    "train_face_label = face_label[:tmp1]\n",
    "test_face_label = face_label[tmp1:]\n",
    "train_face = face[:tmp1,:,:]\n",
    "test_face = face[tmp1:,:,:]\n",
    "\n",
    "# Randomly sampling the non-face data \n",
    "random.seed(42)\n",
    "sample_idx = random.sample(range(len(non_face)), len(face))\n",
    "new_non_face = []\n",
    "new_non_face_label = []\n",
    "for idx in sample_idx:\n",
    "    new_non_face.append(non_face[idx,:,:])\n",
    "    new_non_face_label.append(non_face_label[idx])\n",
    "new_non_face = np.array(new_non_face)\n",
    "new_non_face_label = np.array(new_non_face_label)\n",
    "\n",
    "\n",
    "tmp2 = np.round(new_non_face.shape[0]*train_test_ratio).astype(int)\n",
    "\n",
    "train_non_face_label = new_non_face_label[:tmp2]\n",
    "test_non_face_label = new_non_face_label[tmp2:]\n",
    "train_non_face = new_non_face[:tmp2,:,:]\n",
    "test_non_face = new_non_face[tmp2:,:,:]\n",
    "\n",
    "\n",
    "train_image = np.concatenate((train_face, train_non_face), axis=0)\n",
    "train_label = np.concatenate((train_face_label, train_non_face_label), axis=0)\n",
    "\n",
    "test_image = np.concatenate((test_face, test_non_face), axis=0)\n",
    "test_label = np.concatenate((test_face_label, test_non_face_label), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f7a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(data.Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.images = image_list\n",
    "        self.labels = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff5508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceDataset(train_image, train_label)\n",
    "test_dataset = FaceDataset(test_image, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "071d1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "classes = ('non-face', 'face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dc29c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 32, 32])\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "batch_iterator = iter(train_dataloader)\n",
    "inputs, label = next(batch_iterator)\n",
    "print(inputs.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "designing-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg, size):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=size, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def make_ffn(cfg, size):\n",
    "    input_size = 32\n",
    "    channel_size = cfg[0]\n",
    "    \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            input_size = math.floor(input_size/2)\n",
    "\n",
    "        else:\n",
    "            input_size = math.floor(input_size-size+3)\n",
    "\n",
    "    return nn.Linear(channel_size * input_size * input_size, 2)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, cfg, size):\n",
    "        super().__init__()\n",
    "        self.features = make_layers(cfg, size)\n",
    "        self.fc_layer = make_ffn(cfg, size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e37de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_loader, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    loss_arr = []\n",
    "    start = time.time()\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        # print('--------------------')\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device).float(), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * data.size(0)\n",
    "    \n",
    "        # print('Loss: {:.4f}'.format(epoch_loss))\n",
    "        epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "        loss_arr.append(epoch_loss)\n",
    "\n",
    "    training_time = time.time() - start\n",
    "\n",
    "\n",
    "    return loss_arr, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca3f0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, test_loader):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device).float(), target.to(device)\n",
    "            output = net(data)\n",
    "\n",
    "            preds = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            correct += preds.eq(target.view_as(preds)).sum().item()\n",
    "\n",
    "    acc = correct / len(test_loader.dataset) * 100\n",
    "    print(\"Accuracy of Test Data: {}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f165e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment():\n",
    "    cfgs = [\n",
    "    [8, 'M', 8, 'M'],\n",
    "    [8, 8, 'M', 8, 'M'],\n",
    "    [8, 8, 'M', 8, 8 ,'M'],\n",
    "    [16, 'M', 16, 'M'],\n",
    "    [16, 16, 'M', 16, 'M'],\n",
    "    [16, 16, 'M', 16, 16,'M']\n",
    "    ]\n",
    "\n",
    "    for size in [3,5]:\n",
    "        for num, cfg in enumerate(cfgs):\n",
    "            channel = cfg[0]\n",
    "            \n",
    "            if num in [0,3]:\n",
    "                layer = 2\n",
    "            elif num in [1,4]:\n",
    "                layer = 3\n",
    "            else:\n",
    "                layer = 4\n",
    "            \n",
    "            net = CNN(cfg, size)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.SGD(net.parameters(), lr = 1e-3, momentum=0.9)\n",
    "\n",
    "            train_loss, training_time = train_model(net, train_dataloader, criterion, optimizer, 10)\n",
    "            \n",
    "            plt.plot(np.array(train_loss), 'r')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "\n",
    "            plt.title('Layer: {}, Filter: {}, Size: {}, Time:{:.2f}'.format(layer, channel, size, training_time))\n",
    "\n",
    "            evaluate(net, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c578dff5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1]' is invalid for input of size 131072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000039vscode-remote?line=0'>1</a>\u001b[0m experiment()\n",
      "\u001b[1;32m/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb Cell 13'\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000034vscode-remote?line=29'>30</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000034vscode-remote?line=31'>32</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mLayer: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Filter: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Size: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Time:\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(layer, channel, size, training_time))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000034vscode-remote?line=33'>34</a>\u001b[0m evaluate(net, test_dataloader)\n",
      "\u001b[1;32m/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb Cell 12'\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(net, test_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000031vscode-remote?line=11'>12</a>\u001b[0m         output \u001b[39m=\u001b[39m net(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000031vscode-remote?line=13'>14</a>\u001b[0m         preds \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000031vscode-remote?line=15'>16</a>\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39;49mview_as(preds))\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000031vscode-remote?line=17'>18</a>\u001b[0m acc \u001b[39m=\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/yuwon/PythonProject/CV/Assignment5/Code/CNN_face_noface.ipynb#ch0000031vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy of Test Data: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(acc))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1]' is invalid for input of size 131072"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe294e6606534daba89c1dc14d4f5ef002211ec8430f3955bebe6e14ba2710b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
